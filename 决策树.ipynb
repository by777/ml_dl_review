{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 决策树分类原理"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 熵（Entropy）\n",
    "混乱程度的度量。\n",
    "\n",
    "系统越有序，熵值越低；系统越有序，熵值越高。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1948年⾹农提出了信息熵（Entropy）的概念。\n",
    "信息理论：\n",
    "1. 从信息的完整性上进⾏的描述:\n",
    "当系统的有序状态⼀致时，__数据越集中的地⽅熵值越⼩__，数据越分散的地⽅熵值越⼤。\n",
    "2. 从信息的有序性上进⾏的描述:\n",
    "当数据量⼀致时，系统越有序，熵值越低；系统越混乱或者分散，熵值越⾼。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "“信息熵（information entropy）”是度量样本**集合纯度**最常用的一种指标"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "假定当前样本集合D中第k类样本所占的比例为$p_k,(k=1,2,3,...,|y|)$\n",
    "$p_k = {C^k \\over D}$, D为样本的所有数量，C 为第k类样本的数量。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "则D的信息熵定义为（log以2为底，lg以10为底）\n",
    "![entropy](imgs/ent.png)\n",
    "其中，Ent(D)的值越小，则D的纯度越高"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 案例\n",
    "假设我们没有看世界杯的⽐赛，但是想知道哪⽀球队会是冠军，\n",
    "我们只能猜测某⽀球队是或不是冠军，然后观众⽤对或不对来回答，\n",
    "我们想要猜测次数尽可能少，你会⽤什么⽅法？\n",
    "答案：\n",
    "⼆分法：\n",
    "假如有 16 ⽀球队，分别编号，先问是否在 1-8 之间，如果是就继续问是否在 1-4 之间，\n",
    "以此类推，直到最后判断出冠军球队是哪⽀。\n",
    "如果球队数量是 16，我们需要问 4 次来得到最后的答案。那么世界冠军这条消息的信息熵就是 4。\n",
    "那么信息熵等于4，是如何进⾏计算的呢？\n",
    "Ent(D) = -（p1 * logp1 + p2 * logp2 + ... + p16 * logp16），\n",
    "其中 p1, ..., p16 分别是这 16 ⽀球队夺冠的概率。\n",
    "当每⽀球队夺冠概率相等都是 1/16 的时：Ent(D) = -（16 * 1/16 * log1/16） = 4\n",
    "每个事件概率相同时，熵最⼤，这件事越不确定。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 信息增益\n",
    "信息增益：以某特征划分数据集前后的熵的差值。熵可以表示样本集合的不确定性，熵越⼤，样本的不确定性就越⼤。\n",
    "因此可以使⽤划分前后集合熵的差值来衡量使⽤当前特征对于样本集合D划分效果的好坏。\n",
    "信息增益 = entroy(前) - entroy(后)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}